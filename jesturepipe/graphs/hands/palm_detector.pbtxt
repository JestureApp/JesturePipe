# Graph that takes a image frame and produces palm detections.

type: "PalmDetector"

################################################################################
# Configuration (Input Side Packets)
################################################################################

input_side_packet: "MODEL_PATH:model_path"

################################################################################
# Inputs
################################################################################

# The image frame to find hand landmarks in. (ImageFrame)
input_stream: "IMAGE:frame"

################################################################################
# Outputs
################################################################################

output_stream: "DETECTIONS:detections"

################################################################################
# Graph
################################################################################

node {
    calculator: "ImageToTensorCalculator"
    input_stream: "IMAGE:frame"
    output_stream: "TENSORS:frame_tensor"
    output_stream: "LETTERBOX_PADDING:letterbox_padding"
    options: {
        [mediapipe.ImageToTensorCalculatorOptions.ext]: {
            output_tensor_width: 192
            output_tensor_height: 192
            keep_aspect_ratio: true
            output_tensor_float_range {
                min: 0.0
                max: 1.0
            }
            border_mode: BORDER_ZERO
        }
    }
}

# Generates a single side packet containing a TensorFlow Lite op resolver that
# supports custom ops needed by the model used in this graph.
node {
  calculator: "TfLiteCustomOpResolverCalculator"
  output_side_packet: "OP_RESOLVER:opresolver"
}

# Loads the palm detection TF Lite model.
node {
    calculator: "ModelLoader"
    input_side_packet: "MODEL_PATH:model_path"
    output_side_packet: "MODEL:model"
}

# node {
#     calculator: "PalmDetectionModelLiteCalculator"
#     output_side_packet: "MODEL:model"
# }

# Runs a TensorFlow Lite model on CPU that takes an image tensor and outputs a
# vector of tensors representing, for instance, detection boxes/keypoints and
# scores.
node {
  calculator: "InferenceCalculator"
  input_side_packet: "OP_RESOLVER:opresolver"
  input_side_packet: "MODEL:model"
  input_stream: "TENSORS:frame_tensor"
  output_stream: "TENSORS:detection_tensors"
  options: {
    [mediapipe.InferenceCalculatorOptions.ext] {
      delegate { xnnpack {} }
    }
  }
}

# Generates a single side packet containing a vector of SSD anchors based on
# the specification in the options.
node {
  calculator: "SsdAnchorsCalculator"
  output_side_packet: "anchors"
  options: {
    [mediapipe.SsdAnchorsCalculatorOptions.ext] {
      num_layers: 4
      min_scale: 0.1484375
      max_scale: 0.75
      input_size_width: 192
      input_size_height: 192
      anchor_offset_x: 0.5
      anchor_offset_y: 0.5
      strides: 8
      strides: 16
      strides: 16
      strides: 16
      aspect_ratios: 1.0
      fixed_anchor_size: true
    }
  }
}

# Decodes the detection tensors generated by the TensorFlow Lite model, based on
# the SSD anchors and the specification in the options, into a vector of
# detections. Each detection describes a detected object.
node {
  calculator: "TensorsToDetectionsCalculator"
  input_side_packet: "ANCHORS:anchors"
  input_stream: "TENSORS:detection_tensors"
  output_stream: "DETECTIONS:unfiltered_detections"
  options: {
    [mediapipe.TensorsToDetectionsCalculatorOptions.ext] {
      num_classes: 1
      num_boxes: 2016
      num_coords: 18
      box_coord_offset: 0
      keypoint_coord_offset: 4
      num_keypoints: 7
      num_values_per_keypoint: 2
      sigmoid_score: true
      score_clipping_thresh: 100.0
      reverse_output_order: true

      x_scale: 192.0
      y_scale: 192.0
      w_scale: 192.0
      h_scale: 192.0
      min_score_thresh: 0.5
    }
  }
}

# Performs non-max suppression to remove excessive detections.
node {
  calculator: "NonMaxSuppressionCalculator"
  input_stream: "unfiltered_detections"
  output_stream: "filtered_detections"
  options: {
    [mediapipe.NonMaxSuppressionCalculatorOptions.ext] {
      min_suppression_threshold: 0.3
      overlap_type: INTERSECTION_OVER_UNION
      algorithm: WEIGHTED
    }
  }
}


# Adjusts detection locations (already normalized to [0.f, 1.f]) on the
# letterboxed image (after image transformation with the FIT scale mode) to the
# corresponding locations on the same image with the letterbox removed (the
# input image to the graph before image transformation).
node {
  calculator: "DetectionLetterboxRemovalCalculator"
  input_stream: "DETECTIONS:filtered_detections"
  input_stream: "LETTERBOX_PADDING:letterbox_padding"
  output_stream: "DETECTIONS:detections"
}